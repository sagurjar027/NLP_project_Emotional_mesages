# NLP_project_Emotional_mesages
ğŸ­ Emotion Detection using BiLSTM
ğŸ“Œ Overview

This project performs Emotion Detection on text data using a Bidirectional LSTM (BiLSTM) model.
The dataset contains 416,809 text samples labeled with six emotions:

ğŸ˜¢ Sadness

ğŸ˜€ Joy

â¤ï¸ Love

ğŸ˜¡ Anger

ğŸ˜¨ Fear

ğŸ˜² Surprise

The model achieves ~94% accuracy and is deployed as a Streamlit app for real-time predictions.

ğŸ“‚ Project Structure
emotion_app/
â”‚â”€â”€ app.py                # Streamlit app
â”‚â”€â”€ best_bilstm.h5        # Trained BiLSTM model
â”‚â”€â”€ tokenizer.pkl         # Tokenizer (for preprocessing text)
â”‚â”€â”€ requirements.txt      # Project dependencies
â”‚â”€â”€ README.md             # Project documentation

âš™ï¸ Installation

Clone this repository:

git clone https://github.com/yourusername/emotion-detection-bilstm.git
cd emotion-detection-bilstm


Create a virtual environment and install dependencies:

pip install -r requirements.txt


Make sure you have the model and tokenizer:

best_bilstm.h5 â†’ trained model

tokenizer.pkl â†’ tokenizer object

ğŸ“Š Model Details

Preprocessing: spaCy lemmatization, stopword removal, Keras tokenization, padding (maxlen=20)

Model:

Embedding layer (vocab=10k, dim=100)

BiLSTM (128 units, dropout=0.2)

BatchNormalization + Dropout

Dense(64, relu)

Dense(6, softmax)

Metrics: Accuracy = ~94%, Macro F1 = 0.92

âœ¨ Example Usage

Input:

"I feel so anxious about my exams tomorrow"


Output:

Predicted Emotion: Fear

ğŸ”® Future Work

Add pre-trained embeddings (GloVe / Word2Vec).

Experiment with attention mechanism.

Improve handling of class imbalance.

Extend app with visual analytics (word clouds, charts).

ğŸ‘¨â€ğŸ’» Author: Sahil Kasana
